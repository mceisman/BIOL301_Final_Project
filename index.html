Babe Team's Jupyter Notebook
Members: Gabby D'Haillecourt, Samantha Dibben, Margaret Draeker, and Marley Eisman
Project Overview
Our group, the Babe Team, is exploring the Gompertz Model of Tumor Growth to predict tumor growth rates. This prediction is based on tumor cell images from Figure 1 (A) in [1] that were collected during an eight hour time frame. In order to complete this project, we brushed up on our image analysis skills using scipy and our parameter optimizing techniques (using scipy.optimize) from BIOL 300. Additionally, we took our model analysis skills learned so far from BIOL 301 to help us pick and interpret a tumor growth model.

The main motivation behind chosing this project is how prominent cancer is in society. Cancer is one of the leading causes of death with approximately 1.9 million new cancer diagnoses per year in the United States alone. Of these 1.9 million cases, about 609,000 are expected to result in death, a mortality rate of 1,700 deaths per day [2]. Tracking tumor growth to create a specialized Gompertz model has a variety of applications in terms of preventing these deaths, as well as improving the quality of life for those affected by cancer.

The tumor growth model we decided to use was the Gompertz Curve [3]. The equation and its differential equation are shown below:

X
(
t
)
=
X
(
0
)
e
(
ln
(
K
X
(
0
)
)
(
1
−
e
(
−
α
t
)
)
)
˙
X
(
t
)
=
α
ln
(
K
X
(
t
)
)
X
(
t
)
  
(1)
(2)
 
In these equations, 
X
(
t
)
 is the tumor size as a function of time, 
K
 is the carrying capacity (the maximum size of tumor that can be achieved with the available nutrients), and 
α
 is a constant related to the cells' proliferative ability.

Though there are many different models that show different tumor growth rates, we decided to use the 
X
(
t
)
 model since it was the easiest for us to understand and utilize. The rest of this notebook is dedicated to showing the code we used to process the 17 images (we chose to only include the code for one of the images for simplicity) and how we were able to make our prediction model. All of the images we processed are shown below in the image.

Original Tumor Images from Duke.jpg

Processing the Images
Explanation for Code in This Section
The first step when loading in the image was to separate the bulk image file into the individual time stamp images. Once this was done, an image filter mask (via skimage) was used to eliminate the background noise in each image.

Each tumor image was then further reduced to zoom in on the tumor area of each image. Each image was then measured for pixel intensity and thresholded to give a general guideline of what the threshold value was.

A threshold value was then assigned for each image based off of the histogram of pixel intensity and guess and check attempts. From these thresholded images, the tumor size was then inferred from the total pixels that fell under the thresholded value. The number of pixels was summed and recorded for tumor size reference, and the values were plotted.

Loading in Images
# imports
import numpy as np

# our image processing tools
import skimage
from skimage import io

# plotting libraries
import matplotlib.pyplot as plt

# for numerical integration
import scipy.integrate

# for computing R^2 of graphs
from sklearn.metrics import r2_score
C:\Users\sam04\anaconda3\Lib\site-packages\paramiko\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated
  "class": algorithms.Blowfish,
# Bringing in an image
t_360_base = "Images/My Images to Process (T360-T480)/T_360.tiff"
t_360_im_base = skimage.io.imread(t_360_base)
# Displaying image to ensure it loaded in correctly
plt.imshow(t_360_im_base);

Median Filtering Images
# Median filtering code
# Creating the median filter
selem = skimage.morphology.square(3)
t_360_im_filt = skimage.filters.median(t_360_im_base, selem)

# Displaying to show subtle change
fig, ax = plt.subplots(1, 2, figsize=(12,4))
ax[0].imshow(t_360_im_filt)
ax[0].set_title("Median Filtered")
ax[1].imshow(t_360_im_base)
ax[1].set_title("Original");

Zooming in on the Tumor Area
# The zoom in area greatly depends on the individual photo, so here is one example for T=360
# The filt box works by [left side: right side, up: down]
t_360_im_zoom = t_360_im_filt[53:183, 63:182]

# Making the subplots to show the difference with zooming in on the image
fig, ax = plt.subplots(1, 2, figsize=(12,4))
ax[0].imshow(t_360_im_zoom)
ax[0].set_title("Zoomed in Image with Median Filter")
ax[1].imshow(t_360_im_filt)
ax[1].set_title("Median Filtered Image");

Thresholding Images
# Plotting a histogram of the flattened zoomed in imag
plt.hist(t_360_im_zoom.flatten(), bins=100, color="violet")

# Changing the y-axis to log based
plt.yscale("log")

# Labeling
plt.title("Histogram of Pixel Intensity for $T=360$ Minutes Image")
plt.xlabel("pixel intensity")
plt.ylabel("counts");

# Using the histogram and determing a threshold value -> this part was up to user discretion because the histogram wasn't helpful
thresh = 90

# Turn the image pixels less than the thresholded value into a new image
t_360_im_thresh = t_360_im_zoom < thresh

plt.imshow(t_360_im_thresh);

plt.title("Threshold Image")

# Finding the new pixel count for the thresholded image
t_360_thresh_sum = t_360_im_thresh.sum()

print(f'Pixel count for thresholded image:{t_360_thresh_sum}')
print(f'Pixel count for zoomed image:{t_360_im_zoom.sum()}')
Pixel count for thresholded image:8777
Pixel count for zoomed image:1406427

Saving the Images
# Saving t=360
io.imsave("test.tiff", t_360_im_zoom)
Plotting
Making a List of Thresholded Values and Time Stamps
# Times are from photos, threshold_values are from each person's thresholded images
times = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 360, 390, 420, 450, 480]
threshold_values = [166, 74, 46, 120, 1786, 2145, 3124, 3636, 4548, 5187, 6691, 8370, 8777, 8850, 11350, 11526, 14152]
Plotting the Time vs. Pixel Area
# Using the lists defined above
plt.plot(times, threshold_values, '.', color="orchid")

# Labeling the graph
plt.xlabel('Time (minutes)')
plt.ylabel('Tumor Size (pixels)')
plt.title('Tumor Growth Over Time');

Using scipy.optimize to fit the data to the Gompertz Model of Tumor Growth
# Do initial plotting to get a guesstimate of K and alpha
# Defining values
times = np.linspace(0, 480, 17)
print(f"Time array: {times}")

# Played around with K (carrying capacity) and alpha (cell's proliferative ability) to see what values were in the realm of fitting the data
K = threshold_values[-1]
alpha = 0.01
X_t_guess = threshold_values[0] * np.exp( np.log(K / threshold_values[0]) * (1 - np.exp(- alpha * times)) )

# Plotting
plt.plot(times, X_t_guess, color="lightskyblue")
plt.plot(times, threshold_values, '.', color="orchid")
plt.xlabel('Time (minutes)')
plt.ylabel('Tumor Size (pixels)')
plt.title('Tumor Growth Over Time')
plt.legend(["Parameter Guess", "Image Data"]);
Time array: [  0.  30.  60.  90. 120. 150. 180. 210. 240. 270. 300. 330. 360. 390.
 420. 450. 480.]

# Modifying Chi-Squared function to find best fit for our parameters
def best_fit_gompertz_model(params, data, times):
    """Returns the chi squared value for the parameters, data, and fit arrays provided"""

    # Unpacking the parameters 
    K = params[0]
    alpha = params[1]
    
    # Compute the fit
    fit = threshold_values[0] * np.exp( np.log(K / threshold_values[0]) * (1 - np.exp( - alpha * times)) )
    
    # Computing the chi-squared
    vals = (data - fit) ** 2 / fit
    
    return np.sum(vals)
# Redefining times and threshold values to ensure code is using correct values
times = np.linspace(0, 480, 17)
threshold_values = [166, 74, 46, 120, 1786, 2145, 3124, 3636, 4548, 5187, 6691, 8370, 8777, 8850, 11350, 11526, 14152]

# Optimizing
ans = scipy.optimize.minimize(best_fit_gompertz_model, [14152, 0.006], args=(threshold_values, times),
                       bounds=[ (50, 20000), (0.0001, 3) ] )

# Finding best fit values from ans and printing
print(f"Best K: {ans.x[0]}")
print(f"Best alpha: {ans.x[1]}")
Best K: 14152.000026187941
Best alpha: 0.006113249660119798
# Plotting orginal image data and optimized parameter values
# Gompertz model -> using best fit parameters from above
best_K = ans.x[0]
best_alpha = ans.x[1]

X_t = threshold_values[0] * np.exp( np.log(best_K / threshold_values[0]) * (1 - np.exp(- best_alpha * times)) )
print(f"Calculated X(t) values: {X_t}")

plt.plot(times, X_t, color="lightskyblue")

# Original data
plt.plot(times, threshold_values, '.', color="orchid")

plt.title('Tumor Growth Over Time');
plt.xlabel('Time (minutes)')
plt.ylabel('Tumor Size (pixels)')
plt.title('Tumor Growth Over Time')
plt.legend(["Gompertz Prediction Model", "Image Data"]);
Calculated X(t) values: [  166.           349.64168765   650.02375748  1089.20488874
  1673.88511574  2393.71148574  3223.9457377   4130.80892284
  5077.43991692  6028.91595757  6955.5970475   7834.74302303
  8650.74917516  9394.47749254 10062.1230447  10653.94372647
 11173.06010087]

# Finding the R2 score (coefficient of determination) to see how well the best fit parameters fit our data
r2 = r2_score(threshold_values, X_t)
print(f"R2 value for threshold values vs parameter best fit: {r2}")
R2 value for threshold values vs parameter best fit: 0.9553374209675001
Using Euler's Method for Approximation of Image Data Using Best K and 
α
# Using Euler's method for approximation of Image Data
# Initializing variables
X_0 = threshold_values[0]
K = 14152.00002617755 # best fit K from above
alpha = 0.006113249660270118 # best fit alpha from above

# Parameters for our integration, dt and total_time
dt = 0.01 # minutes
total_time = 480 # minutes

# Determine the number of steps that will be taken
num_steps = int(total_time / dt)

X_euler = np.zeros(num_steps)
X_euler[0] = X_0

# Numerically integrate by looping through X
for t in range(0, num_steps - 1):
    
    # First calculate dN, using previous N entry
    dX = alpha * np.log(K / X_euler[t]) * X_euler[t] * dt
    
    # Update current N entry
    X_euler[t+1] = X_euler[t] + dX

print(f"Euler points for X(t) -> should be very similar to X(t) points that were above: {X_euler}")
Euler points for X(t) -> should be very similar to X(t) points that were above: [  166.           166.04511416   166.09023783 ... 11172.47282081
 11172.63428432 11172.7957403 ]
# Plotting
# Make array of time values -> need to be the same length as their corresponding y, so hence two different time variables
t = np.arange(num_steps)*dt # for Euler graph
times = np.linspace(0, 480, 17) # for original image data and parameter best fit
print(f"Time array for Euler graph: {t}")
print(f"Time array for original image data and parameter best fit: {times}")

# plots
plt.plot(t, X_euler, color="darkgreen")
plt.plot(times, X_t, '--', color="lightskyblue")
plt.plot(times, threshold_values, '.', color="orchid")

plt.xlabel('Time (minutes)')
plt.ylabel('Tumor Size (pixels)')
plt.title("Tumor Growth Over Time")
plt.legend(["Euler's Approximation for $\dot{X}(t)$", "Parameter Best Fit", "Image Data"]);
Time array for Euler graph: [0.0000e+00 1.0000e-02 2.0000e-02 ... 4.7997e+02 4.7998e+02 4.7999e+02]
Time array for original image data and parameter best fit: [  0.  30.  60.  90. 120. 150. 180. 210. 240. 270. 300. 330. 360. 390.
 420. 450. 480.]

Explanation for Code in This Section
We chose to graph our data fitted with the Gompertz model as it is a method currently used in oncology to track tumor growth over time. Our data mostly follows this expected result except near the end where it should plateau but keeps increasing instead. This discrepency is most likely due to the fact that the photos of tumor cells we found were taken over minutes which is quite a short period of time. Whereas if we had found images of tumor cell growth over hours or even days, our graph would most likely follow the Gompertz model even better.

Summary
To recap, our project investigated the Gompertz Model of Tumor Growth to determine if we could predict tumor growth rates. To do this, we found images online showing tumor growth over 480 minutes in cells. With these images we did median filtering, zoomed in on the specific tumor area, and thresholded the images so we could count the number of pixels in a tumor image. Since there were a total of 17 images, we only showed the code for processing one of the images, but the process for each image was the same pipeline. After we processed the images, we made initial guesses at what the parameters 
K
 and 
α
 would be. We inputted these guesses into our scipy.optimize.minimize function to find the best fit of the graph using our selected Gompertz Model of Tumor Growth. We then used Euler's method with the differential equation of the Gompertz Model of Tumor Growth to predict the best fit of our graph. Euler's approximation worked well for this situation because we used a very small 
d
t
.

The feedback we received from the Feedback Workshop was to add more comments in the code along with the descriptions explaining each code section. Another piece of feedback we received was trying to find in the paper we used the units of measurement of the photos so we could have more physical relevance to our graphs. We took a glance back at the research paper we got the images from and the images were measured in units of micrometers. However, the values in the y-axis of our graphs do not align with the rough estimate of areas we calculated directly from the images themselves. Since the trend of our graphs still align with the trend in the images, we decided as a group to leave the y-axis of our graphs in pixels.

Future Applications & Extensions
If more time was available, we would like to expand our interpretation of the Gompertz model to include another term to potentially represent the effect of treatment on tumor growth/decline. Additionally, we would eventually like to generalize this code to take images of tumor growth as inputs and calculate growth rate and the best parameters for the Gompertz fit without requiring individual filtering and thresholding of each image. In this way, this program could be widely applied to predict how a given tumor will grow over time. This would allow medical professionals to assess the efficacy of treatments, as well as predict and prepare for symptoms before they arise.

References
[1] J. M. Bean, E. D. Siggia, and F. R. Cross, “Coherence and Timing of Cell Cycle Start Examined at Single-Cell Resolution,” 
Molecular Cell
, vol. 21, no. 1, pp. 3–14, Jan. 2006, doi: https://doi.org/10.1016/j.molcel.2005.10.035. \ ‌[2] American Cancer Society, “Cancer facts & figures 2021,” 
American Cancer Society
, https://www.cancer.org/research/cancer-facts-statistics/all-cancer-facts-figures/cancer-facts-figures-2021.html#:~:text=Estimated%20numbers%20of%20new%20cancer,deaths%20in%20the%20United%20States. \ [3] B. Heesterman 
e
t
 
a
l
., “Mathematical models for tumor growth and the reduction of overtreatment,” 
J
o
u
r
n
a
l
 
o
f
 
N
e
u
r
o
l
o
g
i
c
a
l
 
S
u
r
g
e
r
y
 
P
a
r
t
 
B
:
 
S
k
u
l
l
 
B
a
s
e
, vol. 80, no. 01, pp. 072–078, Jul. 2018. doi:10.1055/s-0038-1667148

 





